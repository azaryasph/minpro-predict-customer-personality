{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Customer Personality to Boost Marketing Campaign by Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Conversion Rate Analysis Based On Income, Spending And Age\n",
    "Goals : Find a pattern of consumer behavior.<br>\n",
    "Objective : \n",
    "- Feature engineering \n",
    "- Analyze Conversion Rate with other variables such as age, income, expenses, etc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.decomposition import PCA\n",
    "randomstate=511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('./data/marketing_campaign_data.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "New Features :\n",
    "- Age                = age for each customer\n",
    "- AgeGroup           = age group for better interpretation in analysis ahead\n",
    "- Parent             = is the customer have kid or not\n",
    "- NumChild           = how many child do the customer have?\n",
    "- TotalAcceptedCmp   = How many campaigns does the customer receive after the campaign is carried out?\n",
    "- Total Trx          = How many transaction the customer do in our store?\n",
    "- Online Trx         = How many online transaction the customer generate on our platform? \n",
    "- ConversionRate     = the percentage of website visitors who complete a web purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of df for feature engineering\n",
    "dfe = df.copy()\n",
    "\n",
    "# new column age\n",
    "dfe['Age'] = 2024 - dfe['Year_Birth']\n",
    "\n",
    "# new column age group\n",
    "age_grouping = [\n",
    "    (dfe['Age'] >= 60),\n",
    "    (dfe['Age'] >= 40 ) & (dfe['Age'] < 60),\n",
    "    (dfe['Age'] >= 28) & (dfe['Age'] < 40)\n",
    "]\n",
    "age_category = ['Old Adults', 'Middled-aged Adults', 'Young Adults']\n",
    "dfe['AgeGroup'] = np.select(age_grouping, age_category)\n",
    "\n",
    "# new column HasKid\n",
    "def has_kid(row):\n",
    "    if row['Kidhome'] > 0 or row['Teenhome'] > 0:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "dfe['Parent'] = dfe.apply(has_kid, axis=1)\n",
    "\n",
    "# Num child column\n",
    "dfe['NumChild'] = dfe['Kidhome'] + dfe['Teenhome']\n",
    "\n",
    "# new column TotalAcceptedCmp\n",
    "dfe['TotalAcceptedCmp'] = dfe['AcceptedCmp1'] + dfe['AcceptedCmp2'] + dfe['AcceptedCmp3'] + dfe['AcceptedCmp4'] + dfe['AcceptedCmp5']\n",
    "\n",
    "# new column TotalSpending\n",
    "dfe['TotalSpending'] = dfe['MntCoke'] + dfe['MntFruits'] + dfe['MntMeatProducts'] + dfe['MntFishProducts'] + dfe['MntSweetProducts'] + dfe['MntGoldProds']\n",
    "\n",
    "# Total Transaction column\n",
    "dfe['TotalTrx'] = dfe['NumDealsPurchases'] + dfe['NumWebPurchases'] + dfe['NumCatalogPurchases'] + dfe['NumStorePurchases']\n",
    "\n",
    "# Ensure 'Dt_Customer' is in datetime format\n",
    "dfe['Dt_Customer'] = pd.to_datetime(dfe['Dt_Customer'], format='%d-%m-%Y')\n",
    "\n",
    "# Create 'Loyalty' column\n",
    "dfe['Loyalty'] = ((pd.Timestamp.now() - dfe['Dt_Customer']).dt.days / 30.44).astype(int)\n",
    "\n",
    "# ConversionRate column\n",
    "dfe['ConversionRate'] =  dfe['NumWebPurchases'] / dfe['NumWebVisitsMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe[['Education', 'Marital_Status', 'Income','Recency','NumWebVisitsMonth',\n",
    "       'Complain', 'Z_CostContact', 'Z_Revenue', 'Response',\n",
    "       'Age', 'AgeGroup', 'Parent', 'NumChild', 'TotalAcceptedCmp',\n",
    "       'TotalSpending', 'TotalTrx', 'ConversionRate']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe[dfe.ConversionRate.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), facecolor='#E8E8E8')\n",
    "sns.scatterplot(x='Income', y='ConversionRate', data=dfe, color='#D1106F')\n",
    "\n",
    "plt.xlim(0, 200000000)\n",
    "plt.ylim(0, 4.7)\n",
    "\n",
    "plt.axvline(x=110000000, color='b', linestyle='--') \n",
    "\n",
    "plt.title(\"Customer Conversion Rate and Income Correlation\", fontsize=19, fontweight='bold', y=1.02)\n",
    "plt.xlabel('Income', fontsize=13.5)\n",
    "plt.ylabel('Conversion Rate', fontsize=13.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), facecolor='#E8E8E8')\n",
    "sns.scatterplot(x='TotalSpending', y='Income', data=dfe, color='#D1106F')\n",
    "plt.ylim(0, 122000000)\n",
    "plt.xlim(0, 2700000)\n",
    "plt.axvline(x=2540000, color='b', linestyle='--') # Vertical line at x=100000000\n",
    "plt.title('Customer Income and Total Spending Correlation', fontsize=17, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Total Spending', fontsize=13.5)\n",
    "plt.ylabel('Income', fontsize=13.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), facecolor='#E8E8E8')\n",
    "sns.scatterplot(x='TotalSpending', y='ConversionRate', data=dfe, color='#D1106F')\n",
    "plt.ylim(0, 3.8)\n",
    "plt.title('Correlation Between Conversion Rate and Total Spending', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.xlabel('Total Spending', fontsize=13.5)\n",
    "plt.ylabel('Conversion Rate', fontsize=13.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of each age group\n",
    "age_counts = dfe['AgeGroup'].value_counts()\n",
    "palt = ['#00D19B','#D1106F' ,'#25A9D9']\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(12, 8), facecolor='#E8E8E8')\n",
    "patches, texts, autotexts = plt.pie(age_counts, colors=palt, autopct='%1.1f%%', textprops={'size': 13})\n",
    "\n",
    "# Legend\n",
    "plt.legend(patches, age_counts.index, loc=\"best\")\n",
    "\n",
    "plt.title(\"Distribution of Customer by Age Group\", fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of each age group\n",
    "parent_counts = dfe['Parent'].value_counts()\n",
    "palt = ['#00D19B','#D1106F']\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(12, 8), facecolor='#E8E8E8')\n",
    "patches, texts, autotexts = plt.pie(parent_counts, colors=palt, autopct='%1.1f%%', textprops={'size':13})\n",
    "\n",
    "# Add legend\n",
    "plt.legend(patches, parent_counts.index, loc=\"best\")\n",
    "\n",
    "plt.title(\"Parent Customer Distribution\", fontsize=18, fontweight='bold', y=1.02, x=0.54)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 8), facecolor='#E8E8E8')\n",
    "palt = ['#D1106F','#00D19B' ,'#25A9D9']\n",
    "age_order = ['Young Adults', 'Middled-aged Adults', 'Old Adults']\n",
    "barplot = sns.barplot(data=dfe, x='AgeGroup', y='ConversionRate',hue='AgeGroup', order=age_order, legend=False, palette=palt, errorbar=None, edgecolor='black')\n",
    "# Add annotations\n",
    "for p in barplot.patches:\n",
    "    height = p.get_height()\n",
    "    barplot.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 0.01,\n",
    "            '{:1.2f}'.format(height),\n",
    "            ha=\"center\",\n",
    "            fontweight='bold') \n",
    "\n",
    "plt.ylim(0, 1.5)\n",
    "plt.title(\"Conversion Rate by Age Group\", fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Age Group', fontsize=12)\n",
    "plt.ylabel('Conversion Rate', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8), facecolor='#E8E8E8')\n",
    "palt = ['#D1106F','#00D19B' ,'#25A9D9']\n",
    "age_order = ['Young Adults', 'Middled-aged Adults', 'Old Adults']\n",
    "barplot = sns.barplot(data=dfe, x='AgeGroup', y='TotalSpending',hue='AgeGroup', order=age_order, legend=False, palette=palt, errorbar=None, edgecolor='black')\n",
    "\n",
    "# Adding annotations\n",
    "for p in barplot.patches:\n",
    "    barplot.annotate(format(p.get_height(), '.2f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   textcoords = 'offset points',\n",
    "                   fontweight='bold')\n",
    "\n",
    "plt.ylim(0, 820000)\n",
    "plt.title(\"Total Spending by Age Group\", fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Age Group', fontsize=13)\n",
    "plt.ylabel('Total Spending', fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8), facecolor='#E8E8E8')\n",
    "palt = ['#D1106F','#00D19B' ,'#25A9D9']\n",
    "age_order = ['Young Adults', 'Middled-aged Adults', 'Old Adults']\n",
    "barplot = sns.barplot(data=dfe, x='AgeGroup', y='TotalAcceptedCmp',hue='AgeGroup', order=age_order, legend=False, palette=palt, errorbar=None, edgecolor='black')\n",
    "\n",
    "# Adding annotations\n",
    "for p in barplot.patches:\n",
    "    barplot.annotate(format(p.get_height(), '.2f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   textcoords = 'offset points',\n",
    "                   fontweight='bold')\n",
    "\n",
    "# plt.ylim(0, 820000)\n",
    "plt.title(\"Total Spending by Age Group\", fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Age Group', fontsize=13)\n",
    "plt.ylabel('Total Spending', fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), facecolor='#E8E8E8')\n",
    "palt = ['#D1106F','#00D19B' ,'#25A9D9', '#D16F11']\n",
    "barplot = sns.barplot(x='NumChild', y='ConversionRate',hue='NumChild', legend=False, data=dfe, palette=palt, errorbar=None, edgecolor='black')\n",
    "\n",
    "# Adding annotations\n",
    "for p in barplot.patches:\n",
    "    barplot.annotate(format(p.get_height(), '.2f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   textcoords = 'offset points',\n",
    "                   fontweight='bold')\n",
    "\n",
    "plt.ylim(0, 2.2)\n",
    "plt.title(\"Customer Conversion Rate by Number of Children\", fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Number of Children', fontsize=13.5)\n",
    "plt.ylabel('Conversion Rate', fontsize=13.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8), facecolor='#E8E8E8')\n",
    "palt = ['#D1106F','#00D19B']\n",
    "barplot = sns.barplot(x='Parent', y='ConversionRate',hue='Parent', data=dfe, legend=False, palette=palt, errorbar=None, edgecolor='black')\n",
    "\n",
    "# Add annotations\n",
    "for p in barplot.patches:\n",
    "    barplot.annotate(format(p.get_height(), '.2f'), \n",
    "                     (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                     ha = 'center', va = 'center', \n",
    "                     xytext = (0, 10), \n",
    "                     textcoords = 'offset points',\n",
    "                     fontweight='bold')\n",
    "\n",
    "plt.ylim(0, 2.3)\n",
    "plt.title('Conversion Rate by Parental Status', fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Parental Status', fontsize=12)\n",
    "plt.ylabel('Conversion Rate', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8), facecolor='#E8E8E8')\n",
    "palt = ['#D1106F','#00D19B' ,'#25A9D9', '#D16F11', '#6F11D1']\n",
    "ed_order = ['SMA', 'D3', 'S1', 'S2', 'S2']\n",
    "barplot = sns.barplot(x='Education', y='ConversionRate',hue='Education', data=dfe, order=ed_order, legend=False, palette=palt, errorbar=None, edgecolor='black')\n",
    "\n",
    "# Add annotations\n",
    "for p in barplot.patches:\n",
    "    height = p.get_height()\n",
    "    barplot.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 0.01,\n",
    "            '{:1.2f}'.format(height),\n",
    "            ha=\"center\") \n",
    "    \n",
    "plt.ylim(0, 1.28)\n",
    "plt.title('Conversion Rate by Education Level', fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('Education', fontsize=12)\n",
    "plt.ylabel('Conversion Rate', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['Income', 'Recency', 'NumWebVisitsMonth',\n",
    "       'Complain', 'Response', 'Age', 'NumChild', 'TotalAcceptedCmp',\n",
    "       'TotalSpending', 'TotalTrx', 'ConversionRate']\n",
    "plt.figure(figsize=(18,10), facecolor='#E8E8E8')\n",
    "sns.heatmap(dfe[num].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Data Cleaning & Preprocessing\n",
    "Goals : Preparing raw data into clean data ready to be processed by machine learning<br><br>\n",
    "Objective : \n",
    "- Handle Missing Values\n",
    "- Handle Duplicate Values\n",
    "- Handle Infinity values \n",
    "- Feature Selection \n",
    "- Feature Encoding\n",
    "- Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of previous dataframe for next step (Data Preprocessing)\n",
    "dfp = dfe.copy()\n",
    "\n",
    "# Print missing values\n",
    "missing_col = dfp.isna().sum()\n",
    "display_missing_col = missing_col[missing_col > 0]\n",
    "print(f'Missing Values : \\n \\n{display_missing_col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = dfp.isnull().sum()*100 / len(dfp)\n",
    "\n",
    "percentage_missing = pd.DataFrame({'column':dfp.columns,\n",
    "                                   'missing_percentage %':missing.values})\n",
    "percentage_missing['missing_percentage %'] = percentage_missing['missing_percentage %'].round(2)\n",
    "percentage_missig = percentage_missing.sort_values('missing_percentage %', ascending=False)\n",
    "percentage_missing = percentage_missing.reset_index()\n",
    "percentage_missing = percentage_missing.drop('index', axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,8), facecolor='#E8E8E8')\n",
    "ax = sns.barplot(x='missing_percentage %', y='column', data=percentage_missing, color='#E1341E')\n",
    "for p in ax.patches:\n",
    "    ax.annotate('%.2f' % p.get_width() + '%', xy=(p.get_width(), p.get_y()+p.get_height()/2),\n",
    "                xytext=(8,0), textcoords='offset points', ha='left', va='center', fontsize=10)\n",
    "plt.title('Percentage of Missing Data', fontsize=17, fontweight='bold')\n",
    "plt.ylabel('Column', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Percentage', fontsize=12, fontweight='bold')\n",
    "plt.xlim(0,1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cr = dfp[['NumWebPurchases', 'NumWebVisitsMonth', 'ConversionRate']]\n",
    "missing_crdf = missing_cr[missing_cr.isna().any(axis=1)]\n",
    "\n",
    "print(f\"Highlighted Missing values : \\n\")\n",
    "display(missing_crdf)\n",
    "print('*Conversion Rate not missing at Random*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5), facecolor='#E8E8E8')\n",
    "sns.kdeplot(data=dfp, x='Income', fill=True, color='#D1106F')\n",
    "plt.title('Income')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print total null on income and conversion rate\n",
    "total_null_income = dfp['Income'].isna().sum()\n",
    "total_null_conrate = dfp['ConversionRate'].isna().sum()\n",
    "print(f\"Total Missing Values on Income Column = {total_null_income}\")\n",
    "print(f\"Total Missing Values on Conversion Rate Column = {total_null_conrate}\")\n",
    "\n",
    "# print median income\n",
    "median_income = dfp['Income'].median()\n",
    "print(f\"\\nIncome Median to fill the missing value: {median_income}\")\n",
    "\n",
    "# handle missing values with fill and drop method\n",
    "dfp['Income'].fillna(dfp['Income'].median(), inplace=True)\n",
    "dfp.dropna(subset=['ConversionRate'], inplace=True)\n",
    "\n",
    "# checking missing values if still exist\n",
    "nonull_income = dfp['Income'].isna().sum()\n",
    "nonull_conrate = dfp['ConversionRate'].isna().sum()\n",
    "print(f\"\\nMissing Values on Income Column after handling = {nonull_income}\")\n",
    "print(f\"Missing Values on Conversion Rate Column after handling = {nonull_conrate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duplicate = dfp.duplicated().sum()\n",
    "print(f\"Total Duplicated Data = {total_duplicate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix the Infinity Value On Conversion Rate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print count Infiinity values in dataframe\n",
    "count_inf = dfp.map(lambda x: isinstance(x, float) and x == float('inf')).sum().sum()\n",
    "print(f\"Count of Infinity Values :\\nIt Contains {str(count_inf)} Infinite values in dataframe\")\n",
    "\n",
    "# print column where infinity values exist\n",
    "col_inf = dfp.columns[dfp.map(lambda x: isinstance(x, float) and x == float('inf')).any()]\n",
    "print(\"\\nColumns where Infinity values exist:\")\n",
    "print(\", \".join(col_inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinity values with NaN\n",
    "dfp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"Dataframe Entries before dropping infinity values {len(dfp)}\")\n",
    "\n",
    "# Drop infinity value as nan value\n",
    "dfp.dropna(inplace=True)\n",
    "\n",
    "print(f\"\\nDataframe Entries After dropping infinity values {len(dfp)}\")\n",
    "\n",
    "no_inf = dfp.map(lambda x: isinstance(x, float) and x == float('inf')).sum().sum()\n",
    "print(f\"\\nChecking if inifinity values still exist in dataframe : {str(no_inf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, columns):\n",
    "    result = dfp.copy()\n",
    "    for col in columns:\n",
    "        Q1 = result[col].quantile(0.25)\n",
    "        Q3 = result[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        result = result[~((result[col] < (Q1 - 1.5 * IQR)) |(result[col] > (Q3 + 1.5 * IQR)))]\n",
    "    return result\n",
    "\n",
    "outliers = ['Income', 'TotalSpending', 'TotalTrx', 'ConversionRate']\n",
    "dfp = remove_outliers(dfp, outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_slctd = dfp.drop(columns=['Unnamed: 0', 'ID', 'Year_Birth', 'Dt_Customer', 'Z_CostContact', 'Z_Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_slctd = dfp[['Education', 'Marital_Status', 'Income', 'Recency', 'MntCoke',\n",
    "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
    "       'AcceptedCmp2', 'Complain', 'Response',\n",
    "       'Age', 'AgeGroup', 'Parent', 'NumChild', 'TotalAcceptedCmp',\n",
    "       'TotalSpending', 'TotalTrx', 'Loyalty', 'ConversionRate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_slctd = dfp[['Income', 'Recency', 'TotalSpending', 'TotalTrx', 'MntCoke', 'Education', 'Marital_Status',\n",
    "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'AgeGroup', 'Parent', 'NumChild', 'TotalAcceptedCmp',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'ConversionRate', 'Loyalty']].copy()\n",
    "\n",
    "uncssry = ['Unnamed: 0', 'ID', 'Year_Birth', 'Kidhome', 'Teenhome', 'Dt_Customer', 'MntCoke', 'MntFruits', \n",
    "           'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts','MntGoldProds', 'NumDealsPurchases',\n",
    "           'NumWebPurchases','NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3', \n",
    "           'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1','AcceptedCmp2', 'Complain', 'Z_CostContact', 'Z_Revenue', 'Response', 'Age']\n",
    "print(f\"drop unecessary features and redundant features : \\n{uncssry}\")\n",
    "\n",
    "display(dfp_slctd.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Encoding\n",
    "Features to label Encode :<br>\n",
    "- Education\n",
    "- Age Group\n",
    "\n",
    "Features to One Hot Encode: <br>\n",
    "- Marital_Status\n",
    "- Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_slctd = dfp[['Education', 'Marital_Status', 'Income', 'Recency', 'MntCoke',\n",
    "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
    "       'AcceptedCmp2', 'Complain', 'Response',\n",
    "       'Age', 'AgeGroup', 'Parent', 'NumChild', 'TotalAcceptedCmp',\n",
    "       'TotalSpending', 'TotalTrx', 'Loyalty', 'ConversionRate']].copy()\n",
    "# Label Encding\n",
    "# Initialize Label Encoder as le\n",
    "le = LabelEncoder()\n",
    "\n",
    "dfp_slctd['Education'] = le.fit_transform(dfp_slctd['Education'])\n",
    "dfp_slctd['AgeGroup'] = le.fit_transform(dfp_slctd['AgeGroup'])\n",
    "\n",
    "\n",
    "# One hot Encoding\n",
    "ms_encoded = pd.get_dummies(dfp_slctd['Marital_Status'], prefix='Status').astype(int)\n",
    "dfp_slctd = pd.concat([dfp_slctd, ms_encoded], axis=1)\n",
    "\n",
    "parent_encoded = pd.get_dummies(dfp_slctd['Parent'], prefix='Parent').astype(int)\n",
    "dfp_slctd = pd.concat([dfp_slctd, parent_encoded], axis=1)\n",
    "\n",
    "# drop marital status and parent column after encoded(redundant)\n",
    "dfp_slctd.drop(columns=['Marital_Status', 'Parent'], inplace=True)\n",
    "\n",
    "print('\\ndataframe after feature encoding :')\n",
    "display(dfp_slctd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encding\n",
    "# Initialize Label Encoder as le\n",
    "le = LabelEncoder()\n",
    "\n",
    "dfp_slctd['Education'] = le.fit_transform(dfp_slctd['Education'])\n",
    "dfp_slctd['AgeGroup'] = le.fit_transform(dfp_slctd['AgeGroup'])\n",
    "\n",
    "\n",
    "# One hot Encoding\n",
    "ms_encoded = pd.get_dummies(dfp_slctd['Marital_Status'], prefix='Status').astype(int)\n",
    "dfp_slctd = pd.concat([dfp_slctd, ms_encoded], axis=1)\n",
    "\n",
    "parent_encoded = pd.get_dummies(dfp_slctd['Parent'], prefix='Parent').astype(int)\n",
    "dfp_slctd = pd.concat([dfp_slctd, parent_encoded], axis=1)\n",
    "\n",
    "# drop marital status and parent column after encoded(redundant)\n",
    "dfp_slctd.drop(columns=['Marital_Status', 'Parent'], inplace=True)\n",
    "\n",
    "print('\\ndataframe after feature encoding :')\n",
    "display(dfp_slctd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inititalize standard scaler as scaler\n",
    "scaler = StandardScaler()\n",
    "# Standardize the data\n",
    "scaled_data = scaler.fit_transform(dfp_slctd)\n",
    "\n",
    "# new dataframe with scaled data\n",
    "scaled_dfp = pd.DataFrame(scaled_data, columns=dfp_slctd.columns, index=dfp_slctd.index)\n",
    "\n",
    "print('\\ndataframe after scaled(standarized) :')\n",
    "scaled_dfp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 : Modelling\n",
    "Goals : Group customers into several clusters<br><br>\n",
    "Objective : \n",
    "Apply the k-means clustering algorithm to the existing dataset, choose the correct number of clusters by looking at the elbow method, and evaluate using the silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_slctd = dfp[['Education', 'Marital_Status', 'Income', 'Recency', 'MntCoke',\n",
    "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
    "       'AcceptedCmp2', 'Response', 'Parent', 'AgeGroup','NumChild', 'TotalAcceptedCmp',\n",
    "       'TotalSpending', 'TotalTrx', 'Loyalty', 'ConversionRate']].copy()\n",
    "# Label Encding\n",
    "# Initialize Label Encoder as le\n",
    "le = LabelEncoder()\n",
    "\n",
    "dfp_slctd['Education'] = le.fit_transform(dfp_slctd['Education'])\n",
    "dfp_slctd['AgeGroup'] = le.fit_transform(dfp_slctd['AgeGroup'])\n",
    "\n",
    "\n",
    "# One hot Encoding\n",
    "ms_encoded = pd.get_dummies(dfp_slctd['Marital_Status'], prefix='Status').astype(int)\n",
    "dfp_slctd = pd.concat([dfp_slctd, ms_encoded], axis=1)\n",
    "\n",
    "parent_encoded = pd.get_dummies(dfp_slctd['Parent'], prefix='Parent').astype(int)\n",
    "dfp_slctd = pd.concat([dfp_slctd, parent_encoded], axis=1)\n",
    "\n",
    "# drop marital status and parent column after encoded(redundant)\n",
    "dfp_slctd.drop(columns=['Marital_Status', 'Parent'], inplace=True)\n",
    "\n",
    "# Inititalize standard scaler as scaler\n",
    "scaler = StandardScaler()\n",
    "# Standardize the data\n",
    "scaled_data = scaler.fit_transform(dfp_slctd)\n",
    "\n",
    "# new dataframe with scaled data\n",
    "scaled_dfp = pd.DataFrame(scaled_data, columns=dfp_slctd.columns, index=dfp_slctd.index)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "dfpca = pd.DataFrame(pca.fit_transform(scaled_dfp), index=dfp_slctd.index)\n",
    "dfpca.rename(columns={0:'PC1', 1:'PC2'}, inplace=True)\n",
    "\n",
    "inertia = []\n",
    "silhouette = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=randomstate, n_init=\"auto\")\n",
    "    kmeans.fit(dfpca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    cluster_label = kmeans.labels_\n",
    "    silhouette.append(silhouette_score(dfpca, cluster_label))\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "fig.set_facecolor(\"#E8E8E8\")\n",
    "\n",
    "ax1.set_xlabel(\"k\")\n",
    "ax1.set_ylabel(\"inertia score\", color=\"tab:blue\")\n",
    "ax1.plot(\n",
    "    range(2, 10), inertia, marker=\"o\", linestyle=\"--\", color=\"tab:blue\", label=\"inertia\"\n",
    ")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel(\"silhouette score\", color=\"tab:red\")\n",
    "ax2.plot(\n",
    "    range(2, 10),\n",
    "    silhouette,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"tab:red\",\n",
    "    label=\"silhouette\",\n",
    ")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Inertia-Silhouette Score\")\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "dfpca = pd.DataFrame(pca.fit_transform(scaled_dfp), index=dfp_slctd.index)\n",
    "dfpca.rename(columns={0:'PC1', 1:'PC2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal n cluster with Elbow Method and Silhouette Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "silhouette = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=randomstate, n_init=\"auto\")\n",
    "    kmeans.fit(dfpca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    cluster_label = kmeans.labels_\n",
    "    silhouette.append(silhouette_score(dfpca, cluster_label))\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "fig.set_facecolor(\"#E8E8E8\")\n",
    "\n",
    "ax1.set_xlabel(\"k\")\n",
    "ax1.set_ylabel(\"inertia score\", color=\"tab:blue\")\n",
    "ax1.plot(\n",
    "    range(2, 10), inertia, marker=\"o\", linestyle=\"--\", color=\"tab:blue\", label=\"inertia\"\n",
    ")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel(\"silhouette score\", color=\"tab:red\")\n",
    "ax2.plot(\n",
    "    range(2, 10),\n",
    "    silhouette,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"tab:red\",\n",
    "    label=\"silhouette\",\n",
    ")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Inertia-Silhouette Score\")\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "silhouette = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=randomstate, n_init=\"auto\")\n",
    "    kmeans.fit(dfpca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    cluster_label = kmeans.labels_\n",
    "    silhouette.append(silhouette_score(dfpca, cluster_label))\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "fig.set_facecolor(\"#E8E8E8\")\n",
    "\n",
    "ax1.set_xlabel(\"k\")\n",
    "ax1.set_ylabel(\"inertia score\", color=\"tab:blue\")\n",
    "ax1.plot(\n",
    "    range(2, 10), inertia, marker=\"o\", linestyle=\"--\", color=\"tab:blue\", label=\"inertia\"\n",
    ")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel(\"silhouette score\", color=\"tab:red\")\n",
    "ax2.plot(\n",
    "    range(2, 10),\n",
    "    silhouette,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"tab:red\",\n",
    "    label=\"silhouette\",\n",
    ")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Inertia-Silhouette Score\")\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15, 8))\n",
    "fig.set_facecolor(\"#E8E8E8\")\n",
    "for i in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=randomstate, n_init='auto')\n",
    "    q, mod = divmod(i, 2)\n",
    "    visualizer = SilhouetteVisualizer(kmeans, colors=\"yellowbrick\", ax=ax[q - 1][mod])\n",
    "    visualizer.fit(dfpca)\n",
    "    ax[q - 1][mod].set_title(f'Silhouette plot for {i} clusters', fontsize=12, fontweight='bold')\n",
    "    ax[q - 1][mod].set_xlabel('Silhouette Coefficient Values')  # Set x-label\n",
    "    ax[q - 1][mod].set_ylabel('Cluster Label')  # Set y-label\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimal n_cluster = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_optimal = 4\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=randomstate, n_init='auto')\n",
    "kmeans.fit(dfpca)\n",
    "dfpca['cluster'] = kmeans.labels_\n",
    "dfpca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_optimal = 5\n",
    "# kmeans = KMeans(n_clusters=k_optimal, random_state=randomstate, n_init='auto')\n",
    "# kmeans.fit(dfpca)\n",
    "# dfpca.loc[:, 'k_cluster'] = kmeans.predict(dfpca)\n",
    "# dfp_slctd.loc[:, 'k_cluster'] = kmeans.predict(dfpca)\n",
    "# label = dfpca['k_cluster']\n",
    "# dfpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), facecolor='#E8E8E8')\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='cluster', data=dfpca, palette='Set1')\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='black', s=200, alpha=0.8, marker='x')\n",
    "\n",
    "plt.title('K-Means Clustering', fontsize=18, fontweight='bold', y=1.03)\n",
    "plt.xlabel('PCA 1', fontsize=12)\n",
    "plt.ylabel('PCA 2', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust = dfp_slctd.copy()\n",
    "label = dfpca['cluster']\n",
    "df_clust['cluster'] = label\n",
    "# df_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Income', 'TotalSpending', 'ConversionRate', 'Loyalty', 'TotalTrx', 'Recency', 'cluster']\n",
    "features.remove('cluster')\n",
    "\n",
    "n = len(features)\n",
    "ncols = 2\n",
    "nrows = n // ncols if n % ncols == 0 else n // ncols + 1\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(15, nrows*5))\n",
    "\n",
    "# Flatten the axes array\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Create subplots for each feature\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(data=df_clust, y=feature, x='cluster', hue='cluster', palette='Set1', ax=ax[i])\n",
    "    ax[i].set_title(feature)\n",
    "\n",
    "# Remove unused subplots\n",
    "if n < nrows * ncols:\n",
    "    for i in range(n, nrows * ncols):\n",
    "        fig.delaxes(ax[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k_optimal):\n",
    "    print(f'Cluster {i}')\n",
    "    display(dfp_slctd[df_clust['cluster'] == i].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = df_clust.columns.tolist()\n",
    "# features.remove('cluster')\n",
    "\n",
    "# # Create subplots for each feature\n",
    "# for feature in features:\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.boxplot(data=df_clust, y=feature, x='cluster', hue='cluster', palette='Set1')\n",
    "#     plt.title(feature)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
